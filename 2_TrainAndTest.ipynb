{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('us-flight-cleaned-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d7b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2daf004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a07b18",
   "metadata": {},
   "source": [
    "### We are going to predict whether the flight is likely to be delayed or not, i.e., a boolean response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77af87",
   "metadata": {},
   "source": [
    "### Q.) What are the possible models that could be used for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d262ebc",
   "metadata": {},
   "source": [
    "- Logistic regression: Since our target variable is binary classification, the first model that comes to mind is logistic regression.\n",
    "- Linear/Polynomial regression: To see whether this model can be used or not, we need to plot graphs beterrn independent and target variables to see the pattern that is being followed.\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- Support Vector Machines (SVM): SVMs can be used for binary classification, so we can try this. SVMs are useful in handling high-dimensional data, but our data is not high dimensional.\n",
    "- K-Nearest Neighbors (KNN): KNN is useful for small datasets, so not sure how it'll behave here, but we can use it for classification (and regression as well).\n",
    "- Time Series Models: For predicting flight delays based on historical data, time series models like ARIMA (AutoRegressive Integrated Moving Average) or SARIMA (Seasonal ARIMA) can be useful.\n",
    "- Neural Networks: Deep learning models, particularly recurrent neural networks (RNNs) and long short-term memory (LSTM) networks, can capture sequential patterns in flight data, which can be useful for predicting delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3411e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d000235",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cols = ['Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'AirTime']\n",
    "# for col in cols:\n",
    "#     sns.scatterplot(y=df[col], x=df.Delay)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8604dd0",
   "metadata": {},
   "source": [
    "### Let's convert categorical columns to numeric values (because some of the models require that all data be in numerical form, so to keep the process consistent, we'll convert all data to nemerical form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b538f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e26633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Origin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb344cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.OriginCityName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8ed940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.OriginStateName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55628490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Dest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ee8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DestCityName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.DestStateName.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.AirlineName.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a400af",
   "metadata": {},
   "source": [
    "### As seen in EDA, reporting airlines, origin airports, origin cities, origin states, destination airports, destination cities and destination states, all follow a pattern in relation to the number of delayed flights, therefore we can use target encoding for all these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6eb83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AirlineNameNumericalMap = df.groupby('AirlineName')['IsDelayed'].mean().to_dict()\n",
    "OriginAirportNumericalMap = df.groupby('Origin')['IsDelayed'].mean().to_dict()\n",
    "OriginCityNumericalMap = df.groupby('OriginCityName')['IsDelayed'].mean().to_dict()\n",
    "OriginStateNumericalMap = df.groupby('OriginStateName')['IsDelayed'].mean().to_dict()\n",
    "DestAirportNumericalMap = df.groupby('Dest')['IsDelayed'].mean().to_dict()\n",
    "DestCityNumericalMap = df.groupby('DestCityName')['IsDelayed'].mean().to_dict()\n",
    "DestStateNumericalMap = df.groupby('DestStateName')['IsDelayed'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c31ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OriginAirportNumericalMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AirlineNameEncoded'] = df['AirlineName'].map(AirlineNameNumericalMap)\n",
    "df['OriginAirportEncoded'] = df['Origin'].map(OriginAirportNumericalMap)\n",
    "df['OriginCityEncoded'] = df['OriginCityName'].map(OriginCityNumericalMap)\n",
    "df['OriginStateEncoded'] = df['OriginStateName'].map(OriginStateNumericalMap)\n",
    "df['DestAirportEncoded'] = df['Dest'].map(DestAirportNumericalMap)\n",
    "df['DestCityEncoded'] = df['DestCityName'].map(DestCityNumericalMap)\n",
    "df['DestStateEncoded'] = df['DestStateName'].map(DestStateNumericalMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ad4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92645250",
   "metadata": {},
   "source": [
    "Since Reporting_Airline, AirlineName, Origin, OriginCityName, OriginStateName, Dest, DestCityName and DestStateName are not required now, we'll drop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f11ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Reporting_Airline', 'AirlineName', 'Origin', 'OriginCityName', \n",
    "                 'OriginStateName', 'Dest', 'DestCityName', 'DestStateName'], \n",
    "        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('model_ready_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd90818e",
   "metadata": {},
   "source": [
    "### All the columns have been converted into numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c4ed4",
   "metadata": {},
   "source": [
    "## Getting features and target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_not_scaled = df.drop(columns=['Delay', 'IsDelayed'])\n",
    "y_is_delayed = df['IsDelayed']\n",
    "y_delay_time = df['Delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5196fe",
   "metadata": {},
   "source": [
    "## Creating min-max scaled dataframe of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6217d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_to_be_scaled = df.drop(columns=['Delay', 'IsDelayed'])\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_min_max_scaled = min_max_scaler.fit_transform(X_to_be_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e156bcfc",
   "metadata": {},
   "source": [
    "## Creating standardly scaled dataframe of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54843a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "X_standard_scaled = standard_scaler.fit_transform(X_to_be_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e65461",
   "metadata": {},
   "source": [
    "## Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060060d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_performance(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "#     print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, param_grid, X_train, X_test, y_train, y_test, pickile_file_name):\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"Training time: {:.6f} seconds\".format(execution_time))\n",
    "    \n",
    "    accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "    with open(f'{pickile_file_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(grid_search, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049b14aa",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408770d3",
   "metadata": {},
   "source": [
    "Since linear regression is used to predict continuous values, we'll be using the delay (gives the time in minutes by which a flight is delayed) column as the target variable and we will use it to make the prediction for the IsDelayed column based on a threshold value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab991458",
   "metadata": {},
   "source": [
    "### Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_not_scaled, y_delay_time, test_size=0.2, random_state=42)\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "start_time = time.time()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "predictions = linear_reg.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Training time: {:.6f} seconds\".format(execution_time))\n",
    "\n",
    "y_pred = predictions>0\n",
    "y_true = y_test>0\n",
    "\n",
    "print_model_performance(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835cf3b",
   "metadata": {},
   "source": [
    "### With MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f39311",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_min_max_scaled, y_delay_time, test_size=0.2, random_state=42)\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "start_time = time.time()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "predictions = linear_reg.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Training time: {:.6f} seconds\".format(execution_time))\n",
    "\n",
    "y_pred = predictions>0\n",
    "y_true = y_test>0\n",
    "\n",
    "print_model_performance(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ba697",
   "metadata": {},
   "source": [
    "### Standardization (Z-score normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dcc9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_standard_scaled, y_delay_time, test_size=0.2, random_state=42)\n",
    "\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "start_time = time.time()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "predictions = linear_reg.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Training time: {:.6f} seconds\".format(execution_time))\n",
    "\n",
    "y_pred = predictions>0\n",
    "y_true = y_test>0\n",
    "\n",
    "print_model_performance(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548f0ec",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8beca2",
   "metadata": {},
   "source": [
    "There are no such hyperparameters involved in linear regression to be tuned. Although we can use regularization techniques (Ridge/Lasso) to imrove model performance, but the model is already performing so badly, there is no point investing much time on it. There are better models available that we can use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126ccd6",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c53f19",
   "metadata": {},
   "source": [
    "### Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69fa74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_not_scaled, y_delay_time, test_size=0.2, random_state=42)\n",
    "\n",
    "degree = 2\n",
    "polyreg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "\n",
    "start_time = time.time()\n",
    "polyreg.fit(X_train, y_train)\n",
    "poly_predictions = polyreg.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Training time: {:.6f} seconds\".format(execution_time))\n",
    "\n",
    "y_pred = predictions>0\n",
    "y_true = y_test>0\n",
    "\n",
    "print_model_performance(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f17b0e",
   "metadata": {},
   "source": [
    "### With MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_min_max_scaled, y_delay_time, test_size=0.2, random_state=42)\n",
    "\n",
    "degree = 2\n",
    "polyreg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "\n",
    "start_time = time.time()\n",
    "polyreg.fit(X_train, y_train)\n",
    "poly_predictions = polyreg.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Training time: {:.6f} seconds\".format(execution_time))\n",
    "\n",
    "y_pred = predictions>0\n",
    "y_true = y_test>0\n",
    "\n",
    "print_model_performance(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ba00f",
   "metadata": {},
   "source": [
    "### Standardization (Z-score normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_standard_scaled, y_delay_time, test_size=0.2, random_state=42)\n",
    "\n",
    "degree = 2\n",
    "polyreg = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "\n",
    "start_time = time.time()\n",
    "polyreg.fit(X_train, y_train)\n",
    "poly_predictions = polyreg.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Training time: {:.6f} seconds\".format(execution_time))\n",
    "\n",
    "y_pred = predictions>0\n",
    "y_true = y_test>0\n",
    "\n",
    "print_model_performance(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34c791e",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594cb83c",
   "metadata": {},
   "source": [
    "Similar to linear regression, polynomial regression is also performing quite badly, so we'll be focussing more on other models. Again, we can try to tune the hyperparameter - degree of polynomial or use regularization techniques, but the accuracy is already so low, it's a good idea to move on to other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315d6e97",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb7f0e8",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5901063",
   "metadata": {},
   "source": [
    "We'll be using grid search for hyperparameter tuning of models. The inbuilt method GridSearchCV() of sklearn also performs cross-validation internally to get the best model performance, hence we won't be doing cross validation explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],  \n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2819be1",
   "metadata": {},
   "source": [
    "Hyperparameters' meaning:\n",
    "- penalty: Type of regularization used in the model ('l1' (Lasso regression), 'l2' (Ridge regression), 'none' (no regularization))\n",
    "- C: Inverse of regularization strength. Smaller values specify stronger regularization. Regularization helps prevent overfitting by penalizing large coefficients.\n",
    "- solver: Algorithm to use in the optimization problem. The choice of solver can impact the convergence and speed of the optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d214f",
   "metadata": {},
   "source": [
    "### Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb03b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_not_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "pickile_file_name = 'logistic_regression_no_scaling'\n",
    "train_model(LogisticRegression(), param_grid, X_train, X_test, y_train, y_test, pickile_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0ce6d",
   "metadata": {},
   "source": [
    "### With MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_min_max_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "\n",
    "pickile_file_name = 'logistic_regression_min_max_scaling'\n",
    "train_model(LogisticRegression(), param_grid, X_train, X_test, y_train, y_test, pickile_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b84d11",
   "metadata": {},
   "source": [
    "### Standardization (Z-score normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_standard_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "\n",
    "pickile_file_name = 'logistic_regression_standard_scaling'\n",
    "train_model(LogisticRegression(), param_grid, X_train, X_test, y_train, y_test, pickile_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9db67",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9bcd20",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2899a6",
   "metadata": {},
   "source": [
    "Random forst model uses decision trees at its base and since its not a distance based model, scaling should not impact the model performance, hence measuring this model's performance without scaling only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eff8c8",
   "metadata": {},
   "source": [
    "Hyperparameters' meaning:\n",
    "- n_estimators: The number of trees in the forest.\n",
    "- max_depth: The maximum depth of each tree in the forest. Deeper trees can model more complex patterns in the data, but they are more likely to overfit.\n",
    "- min_samples_split: The minimum number of samples required to split an internal node. It specifies the smallest number of samples a node can have to be split further.\n",
    "- min_samples_leaf: The minimum number of samples required to be at a leaf node. It specifies the smallest number of samples a leaf node can have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a91f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5141276",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_not_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "\n",
    "pickile_file_name = 'random_forest'\n",
    "train_model(RandomForestClassifier(random_state=42), param_grid, X_train, X_test, y_train, y_test, \n",
    "            pickile_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d68f7",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c1a1d2",
   "metadata": {},
   "source": [
    "Just like random forest, gradient boosting model also uses decision trees at its base and since its not a distance based model, scaling should not impact the model performance, hence measuring this model's performance without scaling only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86721fc4",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4ff3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c7f6d",
   "metadata": {},
   "source": [
    "Hyperparameters' meaning:\n",
    "- n_estimators: The number of boosting stages to be run. This is the number of trees added to the model.\n",
    "- learning_rate: Shrinks the contribution of each tree.\n",
    "- max_depth: The maximum depth of the individual trees.\n",
    "- min_samples_split: The minimum number of samples required to split an internal node.\n",
    "- min_samples_leaf: The minimum number of samples required to be at a leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_not_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "\n",
    "pickile_file_name = 'gradient_boosting'\n",
    "train_model(GradientBoostingClassifier(random_state=42), param_grid, X_train, X_test, y_train, y_test, \n",
    "            pickile_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8437ee17",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe5f328",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88162499",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce5492",
   "metadata": {},
   "source": [
    "Hyperparameters' meaning:\n",
    "- C: Regularization parameter. It trades off correct classification of training examples against maximization of the decision function's margin. Smaller C encourages a larger margin and a simpler decision function, but may misclassify some points. Larger C penalizes classification mistakes and aims for a more complex decision function that fits the training data better.\n",
    "- kernel: Specifies the kernel type used in the algorithm. Common choices include:\n",
    "    - 'linear': Linear kernel (works well for linearly separable data).\n",
    "    - 'poly': Polynomial kernel.\n",
    "    - 'rbf' (Radial basis function): Gaussian kernel.\n",
    "    - 'sigmoid': Sigmoid kernel.\n",
    "- gamma: Kernel coefficient for 'poly', 'rbf', and 'sigmoid'. Higher values of gamma make the model fit the training data more precisely, potentially leading to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156d0eb",
   "metadata": {},
   "source": [
    "### WIthout scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f5505",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_not_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "\n",
    "pickile_file_name = 'svm_no_scaling'\n",
    "train_model(SVC(random_state=42), param_grid, X_train, X_test, y_train, y_test, pickile_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be7407",
   "metadata": {},
   "source": [
    "### With MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_min_max_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "\n",
    "pickile_file_name = 'svm_min_max_scaling'\n",
    "train_model(SVC(random_state=42), param_grid, X_train, X_test, y_train, y_test, pickile_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed635c1b",
   "metadata": {},
   "source": [
    "### Standardization (Z-score normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecf05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_standard_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "\n",
    "pickile_file_name = 'svm_standard_scaling'\n",
    "train_model(SVC(random_state=42), param_grid, X_train, X_test, y_train, y_test, pickile_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e09d6",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb29fa",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39acef5",
   "metadata": {},
   "source": [
    "Hyperparameters' meaning:\n",
    "- n_neighbors: The number of neighbors to consider when making predictions.\n",
    "- weights: The weight function used in prediction. It can be set to:\n",
    "    - 'uniform': All neighbors have equal weight.\n",
    "    - 'distance': Closer neighbors have a greater influence than neighbors that are farther away.\n",
    "    - A custom function: You can define a custom function that assigns weights to neighbors based on their distance.\n",
    "- algorithm: The algorithm used to compute the nearest neighbors. Options include 'auto', 'ball_tree', 'kd_tree', and 'brute'. The choice of algorithm can impact the speed and memory usage of the KNN model, especially for large datasets.\n",
    "- p: The power parameter for the Minkowski distance metric. When p=1, it corresponds to the Manhattan distance (L1 norm). When p=2, it corresponds to the Euclidean distance (L2 norm). For other values of p, it represents the generalization of Minkowski distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128bf0e",
   "metadata": {},
   "source": [
    "### Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_not_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "\n",
    "pickile_file_name = 'knn_no_scaling'\n",
    "train_model(KNeighborsClassifier(), param_grid, X_train, X_test, y_train, y_test, pickile_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f8041",
   "metadata": {},
   "source": [
    "### With MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86249b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_min_max_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "\n",
    "pickile_file_name = 'knn_min_max_scaling'\n",
    "train_model(KNeighborsClassifier(), param_grid, X_train, X_test, y_train, y_test, pickile_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6fb5fa",
   "metadata": {},
   "source": [
    "### Standardization (Z-score normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285b6e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_standard_scaled, y_is_delayed, test_size=0.2, random_state=42)\n",
    "\n",
    "pickile_file_name = 'knn_standard_scaling'\n",
    "train_model(KNeighborsClassifier(), param_grid, X_train, X_test, y_train, y_test, pickile_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddcb0da",
   "metadata": {},
   "source": [
    "## TO-DO: Can compare performance of time series models and deep learning models as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c028841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
